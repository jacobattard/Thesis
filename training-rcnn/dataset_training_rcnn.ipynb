{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7add0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import copy\n",
    "import csv\n",
    "import time\n",
    "from torchvision.ops import box_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15080f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in handball-detection-8 to voc:: 100%|██████████| 470581/470581 [04:16<00:00, 1832.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to handball-detection-8 in voc:: 100%|██████████| 4647/4647 [00:02<00:00, 1574.39it/s]\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=\"QmzA8vyVJAsptHIaUGx5\")\n",
    "project = rf.workspace(\"penalty-detection\").project(\"handball-detection-op71z\")\n",
    "version = project.version(8)\n",
    "dataset = version.download(\"voc\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84dcafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, annotation_dir, classes):\n",
    "        self.image_dir = image_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.image_files = list(sorted(os.listdir(image_dir)))\n",
    "        self.classes = classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        ann_path = os.path.join(self.annotation_dir, self.image_files[idx].replace(\".jpg\", \".xml\"))\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        tree = ET.parse(ann_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for obj in root.findall(\"object\"):\n",
    "            label = obj.find(\"name\").text\n",
    "            if label not in self.classes:\n",
    "                continue\n",
    "            labels.append(self.classes.index(label))\n",
    "\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            box = [\n",
    "                float(bbox.find(\"xmin\").text),\n",
    "                float(bbox.find(\"ymin\").text),\n",
    "                float(bbox.find(\"xmax\").text),\n",
    "                float(bbox.find(\"ymax\").text)\n",
    "            ]\n",
    "            boxes.append(box)\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "        return ToTensor()(img), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc18123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, valid_loader, device):\n",
    "    model.train()  # keep in train mode so it returns a loss dict\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():  # no gradients, but still returns losses\n",
    "        for images, targets in valid_loader:\n",
    "            images = list(img.to(device) for img in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            val_loss += losses.item()\n",
    "    \n",
    "    return val_loss / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f1d04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"faster_rcnn_results.csv\"\n",
    "with open(csv_file, mode=\"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\n",
    "        \"epoch\", \"time\", \"train_loss\", \"val_loss\",\n",
    "        \"precision\", \"recall\", \"mAP50\", \"mAP50-95\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c04caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, valid_loader, device):\n",
    "    model.eval()\n",
    "    all_precisions, all_recalls, all_map50, all_map5095 = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in valid_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            for output, target in zip(outputs, targets):\n",
    "                gt_boxes = target[\"boxes\"]\n",
    "                pred_boxes = output[\"boxes\"]\n",
    "                scores = output[\"scores\"]\n",
    "\n",
    "                if len(gt_boxes) == 0 or len(pred_boxes) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Sort predictions by confidence\n",
    "                sorted_idx = scores.argsort(descending=True)\n",
    "                pred_boxes = pred_boxes[sorted_idx]\n",
    "\n",
    "                matched_gt = set()\n",
    "                tp, fp = 0, 0\n",
    "\n",
    "                for pb in pred_boxes:\n",
    "                    ious = box_iou(pb.unsqueeze(0), gt_boxes).squeeze(0)\n",
    "                    max_iou, max_idx = ious.max(0)\n",
    "\n",
    "                    if max_iou > 0.5 and max_idx.item() not in matched_gt:\n",
    "                        tp += 1\n",
    "                        matched_gt.add(max_idx.item())\n",
    "                    else:\n",
    "                        fp += 1\n",
    "\n",
    "                fn = len(gt_boxes) - tp\n",
    "\n",
    "                # Precision/Recall\n",
    "                precision = tp / (tp + fp + 1e-6)\n",
    "                recall = tp / (tp + fn + 1e-6)\n",
    "\n",
    "                all_precisions.append(precision)\n",
    "                all_recalls.append(recall)\n",
    "\n",
    "                # mAP@0.5\n",
    "                all_map50.append(precision if tp > 0 else 0.0)\n",
    "\n",
    "                # mAP@0.5:0.95 (still simplified but avoids inflation)\n",
    "                map_scores = []\n",
    "                for thr in [x/100 for x in range(50, 100, 5)]:\n",
    "                    matched_gt = set()\n",
    "                    tp_thr, fp_thr = 0, 0\n",
    "                    for pb in pred_boxes:\n",
    "                        ious = box_iou(pb.unsqueeze(0), gt_boxes).squeeze(0)\n",
    "                        max_iou, max_idx = ious.max(0)\n",
    "                        if max_iou > thr and max_idx.item() not in matched_gt:\n",
    "                            tp_thr += 1\n",
    "                            matched_gt.add(max_idx.item())\n",
    "                        else:\n",
    "                            fp_thr += 1\n",
    "                    fn_thr = len(gt_boxes) - tp_thr\n",
    "                    prec_thr = tp_thr / (tp_thr + fp_thr + 1e-6)\n",
    "                    map_scores.append(prec_thr)\n",
    "                all_map5095.append(sum(map_scores) / len(map_scores))\n",
    "\n",
    "    return (\n",
    "        sum(all_precisions) / len(all_precisions) if all_precisions else 0,\n",
    "        sum(all_recalls) / len(all_recalls) if all_recalls else 0,\n",
    "        sum(all_map50) / len(all_map50) if all_map50 else 0,\n",
    "        sum(all_map5095) / len(all_map5095) if all_map5095 else 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d55a8647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.2457, Val Loss: 0.2034, P: 0.6832, R: 1.0000, mAP50: 0.6832, mAP50-95: 0.4808\n",
      "Epoch 2, Train Loss: 0.1653, Val Loss: 0.1619, P: 0.7961, R: 0.9750, mAP50: 0.7961, mAP50-95: 0.6133\n",
      "Epoch 3, Train Loss: 0.1478, Val Loss: 0.1537, P: 0.8042, R: 0.9822, mAP50: 0.8042, mAP50-95: 0.6303\n",
      "Epoch 4, Train Loss: 0.1304, Val Loss: 0.1384, P: 0.8120, R: 0.9895, mAP50: 0.8120, mAP50-95: 0.6340\n",
      "Epoch 5, Train Loss: 0.1225, Val Loss: 0.1456, P: 0.8044, R: 0.9895, mAP50: 0.8044, mAP50-95: 0.6431\n",
      "Epoch 6, Train Loss: 0.1129, Val Loss: 0.1371, P: 0.8359, R: 0.9804, mAP50: 0.8359, mAP50-95: 0.6520\n",
      "Epoch 7, Train Loss: 0.1086, Val Loss: 0.1506, P: 0.8365, R: 0.9815, mAP50: 0.8365, mAP50-95: 0.6462\n",
      "Epoch 8, Train Loss: 0.1032, Val Loss: 0.1425, P: 0.8952, R: 0.9756, mAP50: 0.8952, mAP50-95: 0.7127\n",
      "Epoch 9, Train Loss: 0.0991, Val Loss: 0.1252, P: 0.8782, R: 0.9814, mAP50: 0.8782, mAP50-95: 0.7164\n",
      "Epoch 10, Train Loss: 0.0945, Val Loss: 0.1334, P: 0.8523, R: 0.9892, mAP50: 0.8523, mAP50-95: 0.6826\n",
      "Epoch 11, Train Loss: 0.0943, Val Loss: 0.1379, P: 0.8543, R: 0.9876, mAP50: 0.8543, mAP50-95: 0.6795\n",
      "Epoch 12, Train Loss: 0.0912, Val Loss: 0.1384, P: 0.8835, R: 0.9809, mAP50: 0.8835, mAP50-95: 0.7124\n",
      "Epoch 13, Train Loss: 0.0881, Val Loss: 0.1331, P: 0.8628, R: 0.9794, mAP50: 0.8628, mAP50-95: 0.6952\n",
      "Epoch 14, Train Loss: 0.0862, Val Loss: 0.1391, P: 0.8839, R: 0.9713, mAP50: 0.8839, mAP50-95: 0.7085\n",
      "Epoch 15, Train Loss: 0.0889, Val Loss: 0.1337, P: 0.8338, R: 0.9856, mAP50: 0.8338, mAP50-95: 0.6658\n",
      "Epoch 16, Train Loss: 0.0865, Val Loss: 0.1348, P: 0.9002, R: 0.9767, mAP50: 0.9002, mAP50-95: 0.7205\n",
      "Epoch 17, Train Loss: 0.0813, Val Loss: 0.1329, P: 0.8770, R: 0.9834, mAP50: 0.8770, mAP50-95: 0.7067\n",
      "Epoch 18, Train Loss: 0.0813, Val Loss: 0.1404, P: 0.8784, R: 0.9811, mAP50: 0.8784, mAP50-95: 0.7040\n",
      "Epoch 19, Train Loss: 0.0813, Val Loss: 0.1328, P: 0.8866, R: 0.9780, mAP50: 0.8866, mAP50-95: 0.7068\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class names, make sure the order matches your annotations\n",
    "classes = [\"__background__\", \"post\", \"handball\"]\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = VOCDataset(\"C:\\\\Users\\\\Jacob\\\\Desktop\\\\Thesis\\\\Code\\\\training-rcnn\\\\handball-detection-8\\\\train\\\\images\", \"C:\\\\Users\\\\Jacob\\\\Desktop\\\\Thesis\\\\Code\\\\training-rcnn\\\\handball-detection-8\\\\train\\\\annotations\", classes)\n",
    "valid_dataset = VOCDataset(\"C:\\\\Users\\\\Jacob\\\\Desktop\\\\Thesis\\\\Code\\\\training\\\\handball-detection-8\\\\valid\\\\images\", \"C:\\\\Users\\\\Jacob\\\\Desktop\\\\Thesis\\\\Code\\\\training-rcnn\\\\handball-detection-8\\\\valid\\\\annotations\", classes)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Model\n",
    "model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, len(classes))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "patience = 10\n",
    "best_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images = list(img.to(device) for img in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += losses.item()\n",
    "\n",
    "    # Train/validation loss\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    val_loss = evaluate_loss(model, valid_loader, device)   # ✅ fixed\n",
    "\n",
    "    # Metrics\n",
    "    precision, recall, mAP50, mAP5095 = evaluate_metrics(model, valid_loader, device)\n",
    "\n",
    "    # Epoch time\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "          f\"P: {precision:.4f}, R: {recall:.4f}, mAP50: {mAP50:.4f}, mAP50-95: {mAP5095:.4f}\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    with open(csv_file, mode=\"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            epoch+1, round(elapsed, 2), round(epoch_loss, 4), round(val_loss, 4),\n",
    "            round(precision, 4), round(recall, 4), round(mAP50, 4), round(mAP5095, 4)\n",
    "        ])\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Restore best model\n",
    "model.load_state_dict(best_model_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e07f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.0890, Val Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "val_loss = evaluate_loss(model, valid_loader, device)\n",
    "print(f\"Epoch {epoch+1}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73ead1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"faster_rcnn_handball.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
